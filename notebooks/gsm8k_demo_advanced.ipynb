{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdaed6c3",
   "metadata": {},
   "source": [
    "# GSM8K: Advanced DSPy Techniques with Local Models\n",
    "\n",
    "This notebook demonstrates advanced DSPy optimization techniques using a local Ollama model (lfm2.5-thinking:latest) on math word problems.\n",
    "\n",
    "**Goal**: Explore cutting-edge DSPy features to maximize performance with local models.\n",
    "\n",
    "## What We'll Cover\n",
    "\n",
    "- Advanced DSPy optimizers (MIPRO)\n",
    "- Chain-of-thought prompting\n",
    "- Multi-stage optimization\n",
    "- Local model integration with Ollama\n",
    "- Performance analysis and comparison\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Ollama installed and running\n",
    "- `lfm2.5-thinking:latest` model pulled: `ollama pull lfm2.5-thinking:latest`\n",
    "- OpenAI API key (for comparison if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b908bf1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c45f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Advanced DSPy imports successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import dspy\n",
    "# MIPRO may not be available in the installed dspy package â€” fall back to the\n",
    "# local wrapper provided in this repository when necessary.\n",
    "try:\n",
    "    from dspy.teleprompt import MIPRO, BootstrapFewShotWithRandomSearch\n",
    "except Exception:\n",
    "    from optimizers.dspy_optimizers import MIPROOptimizer as MIPRO\n",
    "    from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Some dspy versions don't export convenience primitives used in older notebooks;\n",
    "# provide lightweight fallbacks so the notebook runs across dspy releases.\n",
    "try:\n",
    "    from dspy.primitives import assert_transform_module, suggest_transform_module\n",
    "except Exception:\n",
    "    def assert_transform_module(module, *args, **kwargs):\n",
    "        \"\"\"Fallback that assumes module is valid (used only for demos).\"\"\"\n",
    "        return True\n",
    "\n",
    "    def suggest_transform_module(module, *args, **kwargs):\n",
    "        \"\"\"Fallback stub returning None for suggestions.\"\"\"\n",
    "        return None\n",
    "\n",
    "from data import prepare_gsm8k_splits, gsm8k_metric, evaluate_gsm8k\n",
    "from modules import MathSolver\n",
    "from baselines import create_baseline\n",
    "from utils import Evaluator\n",
    "from config import DATASET_CONFIGS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ Advanced DSPy imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b06c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Ollama model...\n",
      "âŒ Model test failed: litellm.APIConnectionError: OllamaException - Illegal header value b'Bearer '\n",
      "Make sure Ollama is running and the model is pulled.\n",
      "âœ“ Configured DSPy with Ollama lfm2.5-thinking:latest\n"
     ]
    }
   ],
   "source": [
    "# Configure Ollama model\n",
    "ollama_lm = dspy.LM(\n",
    "    model=\"ollama/lfm2.5-thinking:latest\",\n",
    "    api_base=\"http://localhost:11434/v1\",\n",
    "    api_key=None,  # don't send empty Bearer header to Ollama\n",
    "    max_tokens=4096,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing Ollama model...\")\n",
    "try:\n",
    "    response = ollama_lm(\"What is 2+2?\")\n",
    "    print(f\"âœ“ Model response: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Model test failed: {e}\")\n",
    "    print(\"Make sure Ollama is running and the model is pulled.\")\n",
    "\n",
    "# Configure DSPy\n",
    "dspy.settings.configure(lm=ollama_lm)\n",
    "\n",
    "print(\"âœ“ Configured DSPy with Ollama lfm2.5-thinking:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7e2c5",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75724b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GSM8K splits\n",
    "config = DATASET_CONFIGS['gsm8k'].copy()\n",
    "config['dev_size'] = 100  # Smaller for faster iteration\n",
    "\n",
    "train_examples, dev_examples, test_examples = prepare_gsm8k_splits(\n",
    "    train_size=config['train_size'],\n",
    "    dev_size=config['dev_size'],\n",
    "    test_size=config['test_size'],\n",
    "    seed=config['seed'],\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Data loaded:\")\n",
    "print(f\"  Train: {len(train_examples)} examples\")\n",
    "print(f\"  Dev:   {len(dev_examples)} examples\")\n",
    "print(f\"  Test:  {len(test_examples)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69258b55",
   "metadata": {},
   "source": [
    "## 3. Advanced DSPy Module with Chain-of-Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced math solver with chain-of-thought\n",
    "class AdvancedMathSolver(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.solve = dspy.ChainOfThought(\"question -> reasoning, answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.solve(question=question)\n",
    "\n",
    "# Test the advanced module\n",
    "advanced_solver = AdvancedMathSolver()\n",
    "test_example = train_examples[0]\n",
    "\n",
    "print(\"Testing Advanced Math Solver:\")\n",
    "print(f\"Question: {test_example.question}\")\n",
    "result = advanced_solver.forward(question=test_example.question)\n",
    "print(f\"Reasoning: {result.reasoning}\")\n",
    "print(f\"Answer: {result.answer}\")\n",
    "print(f\"Expected: {test_example.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ee2dd",
   "metadata": {},
   "source": [
    "## 4. MIPRO Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIPRO (Multi-Instructor Prompt Optimization)\n",
    "mipro_kwargs = dict(\n",
    "    metric=gsm8k_metric,\n",
    "    num_candidates=10,  # Generate 10 candidate programs\n",
    "    init_temperature=1.0,  # High temperature for diverse initial prompts\n",
    ")\n",
    "\n",
    "print(\"Starting MIPRO optimization...\")\n",
    "print(\"This will generate multiple candidate programs and select the best one.\")\n",
    "\n",
    "# Instantiate with compatibility for either dspy.MIPRO or the local wrapper\n",
    "try:\n",
    "    mipro_optimizer = MIPRO(**mipro_kwargs, verbose=True, num_threads=4)\n",
    "except TypeError:\n",
    "    mipro_optimizer = MIPRO(**mipro_kwargs)\n",
    "\n",
    "optimized_solver = mipro_optimizer.compile(\n",
    "    AdvancedMathSolver(),\n",
    "    trainset=train_examples[:30],  # Smaller training set for demo\n",
    "    valset=dev_examples[:30],      # provide validation set (required by some optimizers)\n",
    "    eval_kwargs=dict(num_threads=4, display_table=False),\n",
    ")\n",
    "\n",
    "print(\"âœ“ MIPRO optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0393aa",
   "metadata": {},
   "source": [
    "## 5. Evaluation with Concurrent Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0960988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all approaches\n",
    "evaluator = Evaluator(\n",
    "    metric_fn=gsm8k_metric, \n",
    "    show_progress=True, \n",
    "    verbose=False, \n",
    "    max_concurrent=5  # Concurrent evaluation\n",
    ")\n",
    "\n",
    "# Zero-shot baseline\n",
    "zero_shot = create_baseline(\"zero-shot\", \"gsm8k\", ollama_lm)\n",
    "zero_shot_result = evaluator.evaluate(\n",
    "    zero_shot, dev_examples, \"Zero-Shot (Ollama)\", \"gsm8k\"\n",
    ")\n",
    "\n",
    "# Few-shot baseline\n",
    "few_shot = create_baseline(\"few-shot\", \"gsm8k\", ollama_lm, num_examples=3)\n",
    "few_shot_result = evaluator.evaluate(\n",
    "    few_shot, dev_examples, \"Few-Shot (Ollama)\", \"gsm8k\"\n",
    ")\n",
    "\n",
    "# DSPy optimized\n",
    "dspy_result = evaluator.evaluate(\n",
    "    optimized_solver, dev_examples, \"DSPy MIPRO (Ollama)\", \"gsm8k\"\n",
    ")\n",
    "\n",
    "print(\"\n",
    "ðŸ“Š Results Summary:\")\n",
    "print(f\"Zero-Shot: {zero_shot_result.accuracy:.1%}\")\n",
    "print(f\"Few-Shot: {few_shot_result.accuracy:.1%}\")\n",
    "print(f\"DSPy MIPRO: {dspy_result.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2efacbc",
   "metadata": {},
   "source": [
    "## 6. Inspect Optimized Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect what MIPRO learned\n",
    "print(\"Optimized Program Structure:\")\n",
    "print(optimized_solver)\n",
    "\n",
    "# Test on a few examples\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i in range(3):\n",
    "    example = dev_examples[i]\n",
    "    pred = optimized_solver(question=example.question)\n",
    "    correct = gsm8k_metric(example, pred) > 0.5\n",
    "    print(f\"\\nExample {i+1}: {'âœ“' if correct else 'âœ—'}\")\n",
    "    print(f\"Question: {example.question[:60]}...\")\n",
    "    print(f\"Predicted: {pred.answer}\")\n",
    "    print(f\"Expected: {example.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60661e",
   "metadata": {},
   "source": [
    "## 7. Advanced DSPy Insights\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **MIPRO vs BootstrapFewShot**: MIPRO generates multiple candidate programs and uses Bayesian optimization to find the best one\n",
    "2. **Chain-of-Thought**: Explicit reasoning steps help local models perform better\n",
    "3. **Local Models**: Ollama models can achieve good performance with proper optimization\n",
    "4. **Concurrent Processing**: Speeds up both optimization and evaluation\n",
    "\n",
    "### Advanced Techniques Used\n",
    "\n",
    "- **MIPRO Optimizer**: Multi-instructor prompt optimization\n",
    "- **ChainOfThought Signature**: Forces step-by-step reasoning\n",
    "- **Bayesian Optimization**: Efficiently searches prompt space\n",
    "- **Parallel Processing**: Concurrent API calls for speed\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "- Try different local models (Mixtral, Llama variants)\n",
    "- Experiment with assertion-based optimization\n",
    "- Add multi-stage reasoning pipelines\n",
    "- Implement custom metrics and constraints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
