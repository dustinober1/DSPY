{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdaed6c3",
   "metadata": {},
   "source": [
    "# GSM8K: Advanced DSPy Techniques with Local Models\n",
    "\n",
    "This notebook demonstrates advanced DSPy optimization techniques using a local Ollama model (lfm2.5-thinking:latest) on math word problems.\n",
    "\n",
    "**Goal**: Explore cutting-edge DSPy features to maximize performance with local models.\n",
    "\n",
    "## What We'll Cover\n",
    "\n",
    "- Advanced DSPy optimizers (MIPRO)\n",
    "- Chain-of-thought prompting\n",
    "- Multi-stage optimization\n",
    "- Local model integration with Ollama\n",
    "- Performance analysis and comparison\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Ollama installed and running\n",
    "- `lfm2.5-thinking:latest` model pulled: `ollama pull lfm2.5-thinking:latest`\n",
    "- OpenAI API key (for comparison if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b908bf1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c45f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Advanced DSPy imports successful\n",
      "\u2713 Using optimizer class: MIPROv2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path (works from repo root or notebooks/)\n",
    "cwd = Path.cwd()\n",
    "project_root = cwd if (cwd / \"config.py\").exists() else cwd.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import dspy\n",
    "# Prefer MIPROv2 on modern DSPy, then legacy MIPRO, then local wrapper fallback.\n",
    "try:\n",
    "    from dspy.teleprompt import MIPROv2 as MIPRO, BootstrapFewShotWithRandomSearch\n",
    "    MIPRO_NAME = \"MIPROv2\"\n",
    "except Exception:\n",
    "    try:\n",
    "        from dspy.teleprompt import MIPRO, BootstrapFewShotWithRandomSearch\n",
    "        MIPRO_NAME = \"MIPRO\"\n",
    "    except Exception:\n",
    "        from optimizers.dspy_optimizers import MIPROOptimizer as MIPRO\n",
    "        from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "        MIPRO_NAME = \"MIPROOptimizer wrapper\"\n",
    "\n",
    "# Some dspy versions don't export convenience primitives used in older notebooks;\n",
    "# provide lightweight fallbacks so the notebook runs across dspy releases.\n",
    "try:\n",
    "    from dspy.primitives import assert_transform_module, suggest_transform_module\n",
    "except Exception:\n",
    "    def assert_transform_module(module, *args, **kwargs):\n",
    "        \"\"\"Fallback that assumes module is valid (used only for demos).\"\"\"\n",
    "        return True\n",
    "\n",
    "    def suggest_transform_module(module, *args, **kwargs):\n",
    "        \"\"\"Fallback stub returning None for suggestions.\"\"\"\n",
    "        return None\n",
    "\n",
    "from dspy.utils.exceptions import AdapterParseError\n",
    "\n",
    "from data import prepare_gsm8k_splits, gsm8k_metric, evaluate_gsm8k\n",
    "from modules import MathSolver\n",
    "from baselines import create_baseline\n",
    "from utils import Evaluator\n",
    "from config import DATASET_CONFIGS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\u2713 Advanced DSPy imports successful\")\n",
    "print(f\"\u2713 Using optimizer class: {MIPRO_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18b06c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Ollama model...\n",
      "\u2713 Model response: [{'text': '\\n\\n2 + 2 equals **4**. Simple math! \ud83d\ude0a Let me know if you need further clarification.', 'reasoning_content': ' Okay, let\\'s see. The user asked \"What is 2+2?\" and I need to respond appropriately. Hmm, the question seems straightforward, but maybe there\\'s a trick here. Wait, the user mentioned \"User: What is 2+2?\" and I have to figure out what they expect. Since it\\'s a simple math question, the answer is probably just 4. But maybe they want some deeper explanation? Or perhaps there\\'s a context I\\'m missing. Let me think.\\n\\nWait, sometimes people play with questions like \"What is 2+2?\" expecting a play on words or a pun. But 2+2 is obviously 4. Unless there\\'s a context where 2+2 represents something else, like in a different base? For example, in base 3, 2+2 would be 11 (since 2+2=4, which is 1*3 +1=4? Wait no, 4 in base 3 is 11 (1*3 +1=4). But the question is in base 10 probably. Alternatively, maybe the user is testing if I know that 2+2 is 4. Alternatively, maybe they want a joke answer? Like \"It\\'s 4 because...\", but I should stick to the basic answer unless instructed otherwise.\\n\\nAlternatively, maybe the user is expecting a different approach. Let me confirm: 2 plus 2 equals 4. So the answer is 4. I should just state that clearly. But since the user might be expecting a trick, but I can\\'t think of any. So I\\'ll go with 4. Just make sure to present it simply.\\n'}]\n",
      "\u2713 Configured DSPy with Ollama lfm2.5-thinking:latest\n",
      "\u2713 Enabled JSONAdapter(use_native_function_calling=False) for parse stability\n"
     ]
    }
   ],
   "source": [
    "# Configure Ollama model\n",
    "ollama_lm = dspy.LM(\n",
    "    model=\"ollama/lfm2.5-thinking:latest\",\n",
    "    api_base=\"http://localhost:11434\",\n",
    "    api_key=None,  # don't send empty Bearer header to Ollama\n",
    "    max_tokens=1536,\n",
    "    temperature=0.0,  # deterministic output improves DSPy parse reliability\n",
    "    num_retries=6,\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing Ollama model...\")\n",
    "try:\n",
    "    response = ollama_lm(\"What is 2+2?\")\n",
    "    print(f\"\u2713 Model response: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Model test failed: {e}\")\n",
    "    print(\"Make sure Ollama is running and the model is pulled.\")\n",
    "\n",
    "# Configure DSPy\n",
    "# Reasoning models on local providers are often more stable with JSON mode\n",
    "# instead of native tool/function-calling structured output.\n",
    "json_adapter = dspy.JSONAdapter(use_native_function_calling=False)\n",
    "dspy.settings.configure(lm=ollama_lm, adapter=json_adapter, max_errors=50)\n",
    "\n",
    "print(\"\u2713 Configured DSPy with Ollama lfm2.5-thinking:latest\")\n",
    "print(\"\u2713 Enabled JSONAdapter(use_native_function_calling=False) for parse stability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7e2c5",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75724b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GSM8K train split...\n",
      "Loaded 300 examples from GSM8K train\n",
      "Loading GSM8K test split...\n",
      "Loaded 100 examples from GSM8K test\n",
      "\n",
      "Prepared GSM8K splits:\n",
      "  Train: 200 examples\n",
      "  Dev:   100 examples\n",
      "  Test:  100 examples\n",
      "\u2713 Data loaded:\n",
      "  Train: 200 examples\n",
      "  Dev:   100 examples\n",
      "  Test:  100 examples\n"
     ]
    }
   ],
   "source": [
    "# Load GSM8K splits\n",
    "config = DATASET_CONFIGS['gsm8k'].copy()\n",
    "\n",
    "train_examples, dev_examples, test_examples = prepare_gsm8k_splits(\n",
    "    train_size=config['train_size'],\n",
    "    dev_size=config['dev_size'],\n",
    "    test_size=config['test_size'],\n",
    "    seed=config['seed'],\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Data loaded:\")\n",
    "print(f\"  Train: {len(train_examples)} examples\")\n",
    "print(f\"  Dev:   {len(dev_examples)} examples\")\n",
    "print(f\"  Test:  {len(test_examples)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69258b55",
   "metadata": {},
   "source": [
    "## 3. Advanced DSPy Module with Chain-of-Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14ba1348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/13 18:03:36 WARNING dspy.primitives.module: Calling module.forward(...) on AdvancedMathSolver directly is discouraged. Please use module(...) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Advanced Math Solver:\n",
      "Question: Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?\n",
      "Reasoning: Kyle found twice as many shells as Mimi (2 dozen * 2 = 4 dozen = 48 shells), Leigh grabbed one-third of Kyle's shells (48 / 3 = 16), so Leigh has 16.\n",
      "Answer: 16\n",
      "Expected: 16\n"
     ]
    }
   ],
   "source": [
    "def extract_last_number(text: str) -> str:\n",
    "    \"\"\"Extract the final numeric token from model text.\"\"\"\n",
    "    cleaned = str(text).replace(',', '')\n",
    "    matches = re.findall(r'-?\\d+(?:\\.\\d+)?', cleaned)\n",
    "    if not matches:\n",
    "        return \"\"\n",
    "\n",
    "    candidate = matches[-1]\n",
    "    try:\n",
    "        value = float(candidate)\n",
    "        return str(int(value)) if value.is_integer() else str(value)\n",
    "    except ValueError:\n",
    "        return candidate\n",
    "\n",
    "\n",
    "def extract_reasoning_field(raw_response: str) -> str:\n",
    "    \"\"\"Recover the reasoning field when JSON output is truncated.\"\"\"\n",
    "    text = str(raw_response).strip()\n",
    "    match = re.search(r'\\\"reasoning\\\"\\s*:\\s*\\\"((?:\\\\.|[^\\\"\\\\])*)', text, flags=re.DOTALL)\n",
    "    if not match:\n",
    "        return text\n",
    "\n",
    "    encoded = match.group(1)\n",
    "    try:\n",
    "        return bytes(encoded, 'utf-8').decode('unicode_escape').strip()\n",
    "    except Exception:\n",
    "        return encoded.strip()\n",
    "\n",
    "\n",
    "# Create advanced math solver with chain-of-thought\n",
    "class AdvancedMathSolver(dspy.Module):\n",
    "    def __init__(self, max_parse_retries: int = 2):\n",
    "        super().__init__()\n",
    "        self.solve = dspy.ChainOfThought(\"question -> reasoning, answer\")\n",
    "        self.answer_only = dspy.Predict(\"question -> answer\")\n",
    "        self.max_parse_retries = max_parse_retries\n",
    "\n",
    "    def _fallback_prediction(self, error: Exception, question: str):\n",
    "        raw = getattr(error, \"lm_response\", \"\") or str(error)\n",
    "        reasoning = extract_reasoning_field(raw)\n",
    "        answer = extract_last_number(reasoning) or extract_last_number(raw)\n",
    "\n",
    "        if not answer:\n",
    "            # Final fallback: ask for answer-only output (single field is easier to parse).\n",
    "            try:\n",
    "                answer_text = str(self.answer_only(question=question).answer).strip()\n",
    "                answer = extract_last_number(answer_text) or answer_text\n",
    "            except Exception:\n",
    "                answer = \"\"\n",
    "\n",
    "        return dspy.Prediction(reasoning=reasoning, answer=answer)\n",
    "\n",
    "    def forward(self, question):\n",
    "        last_error = None\n",
    "        for _ in range(self.max_parse_retries):\n",
    "            try:\n",
    "                return self.solve(question=question)\n",
    "            except AdapterParseError as error:\n",
    "                last_error = error\n",
    "\n",
    "        if last_error is not None:\n",
    "            return self._fallback_prediction(last_error, question)\n",
    "\n",
    "        # Defensive fallback for unexpected control flow.\n",
    "        return dspy.Prediction(reasoning=\"\", answer=\"\")\n",
    "\n",
    "\n",
    "# Test the advanced module\n",
    "advanced_solver = AdvancedMathSolver()\n",
    "test_example = train_examples[0]\n",
    "\n",
    "print(\"Testing Advanced Math Solver:\")\n",
    "print(f\"Question: {test_example.question}\")\n",
    "result = advanced_solver.forward(question=test_example.question)\n",
    "print(f\"Reasoning: {result.reasoning}\")\n",
    "print(f\"Answer: {result.answer}\")\n",
    "print(f\"Expected: {test_example.answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ee2dd",
   "metadata": {},
   "source": [
    "## 4. MIPRO Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d141df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MIPRO optimization...\n",
      "This will generate multiple candidate programs and select the best one.\n",
      "Optimizer backend: MIPROv2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If auto is None, num_trials must also be provided. Given num_candidates=10, we'd recommend setting num_trials to ~26.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     optimized_solver = \u001b[43mmipro_optimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mAdvancedMathSolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompile_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_table\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: MIPROv2.compile() got an unexpected keyword argument 'eval_kwargs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     31\u001b[39m     optimized_solver = mipro_optimizer.compile(\n\u001b[32m     32\u001b[39m         AdvancedMathSolver(),\n\u001b[32m     33\u001b[39m         **compile_kwargs,\n\u001b[32m     34\u001b[39m         eval_kwargs=\u001b[38;5;28mdict\u001b[39m(num_threads=\u001b[32m2\u001b[39m, display_table=\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m     35\u001b[39m     )\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     optimized_solver = \u001b[43mmipro_optimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mAdvancedMathSolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompile_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\u2713 MIPRO optimization complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/DSPY/.venv/lib/python3.13/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:142\u001b[39m, in \u001b[36mMIPROv2.compile\u001b[39m\u001b[34m(self, student, trainset, teacher, valset, num_trials, max_bootstrapped_demos, max_labeled_demos, seed, minibatch, minibatch_size, minibatch_full_eval_steps, program_aware_proposer, data_aware_proposer, view_data_batch_size, tip_aware_proposer, fewshot_aware_proposer, requires_permission_to_run, provide_traceback)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# If auto is None, and num_trials is not provided (but num_candidates is), raise an error that suggests a good num_trials value\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.num_candidates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m num_trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    143\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIf auto is None, num_trials must also be provided. Given num_candidates=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_candidates\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, we\u001b[39m\u001b[33m'\u001b[39m\u001b[33md recommend setting num_trials to ~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._set_num_trials_from_num_candidates(student,\u001b[38;5;250m \u001b[39mzeroshot_opt,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.num_candidates)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    144\u001b[39m     )\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# If auto is None, and num_candidates or num_trials is None, raise an error\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.num_candidates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[31mValueError\u001b[39m: If auto is None, num_trials must also be provided. Given num_candidates=10, we'd recommend setting num_trials to ~26."
     ]
    }
   ],
   "source": [
    "# MIPRO (Multi-Instructor Prompt Optimization)\n",
    "mipro_kwargs = dict(\n",
    "    metric=gsm8k_metric,\n",
    "    num_candidates=10,  # Candidate prompts/programs\n",
    "    init_temperature=1.0,  # High temperature for diverse initial prompts\n",
    ")\n",
    "\n",
    "print(\"Starting MIPRO optimization...\")\n",
    "print(\"This will generate multiple candidate programs and select the best one.\")\n",
    "print(f\"Optimizer backend: {MIPRO_NAME}\")\n",
    "\n",
    "# Instantiate with signature-aware kwargs so this works across MIPROv2/MIPRO/wrapper.\n",
    "mipro_init_sig = inspect.signature(MIPRO).parameters\n",
    "mipro_init = dict(mipro_kwargs)\n",
    "if \"verbose\" in mipro_init_sig:\n",
    "    mipro_init[\"verbose\"] = True\n",
    "if \"num_threads\" in mipro_init_sig:\n",
    "    mipro_init[\"num_threads\"] = 2\n",
    "if MIPRO_NAME == \"MIPROv2\" and mipro_init.get(\"num_candidates\") is not None and \"auto\" in mipro_init_sig:\n",
    "    # DSPy MIPROv2 requires auto=None when num_candidates is explicitly set.\n",
    "    mipro_init[\"auto\"] = None\n",
    "mipro_optimizer = MIPRO(**mipro_init)\n",
    "\n",
    "compile_kwargs = dict(\n",
    "    trainset=train_examples[:30],  # Smaller training set for demo\n",
    "    valset=dev_examples[:30],      # Validation set (required by some optimizers)\n",
    ")\n",
    "\n",
    "compile_sig = inspect.signature(mipro_optimizer.compile).parameters\n",
    "if \"eval_kwargs\" in compile_sig:\n",
    "    compile_kwargs[\"eval_kwargs\"] = dict(num_threads=2, display_table=False)\n",
    "\n",
    "# MIPROv2 constraint from DSPy docs:\n",
    "# if auto=None and num_candidates is set, num_trials must also be provided.\n",
    "if MIPRO_NAME == \"MIPROv2\":\n",
    "    auto_setting = getattr(mipro_optimizer, \"auto\", None)\n",
    "    num_candidates = getattr(mipro_optimizer, \"num_candidates\", None)\n",
    "    if auto_setting is None and num_candidates is not None and compile_kwargs.get(\"num_trials\") is None:\n",
    "        compile_kwargs[\"num_trials\"] = max(1, int(round(2.6 * int(num_candidates))))\n",
    "        print(\n",
    "            f\"Configured MIPROv2 num_trials={compile_kwargs['num_trials']} \"\n",
    "            f\"(auto=None, num_candidates={num_candidates})\"\n",
    "        )\n",
    "\n",
    "    # MIPROv2 default minibatch_size=35 can exceed our small valset.\n",
    "    valset_size = len(compile_kwargs[\"valset\"])\n",
    "    if compile_kwargs.get(\"minibatch\", True):\n",
    "        requested_minibatch_size = int(compile_kwargs.get(\"minibatch_size\", 35))\n",
    "        if requested_minibatch_size > valset_size:\n",
    "            compile_kwargs[\"minibatch_size\"] = valset_size\n",
    "            print(\n",
    "                f\"Adjusted MIPROv2 minibatch_size={valset_size} \"\n",
    "                f\"to match valset size\"\n",
    "            )\n",
    "\n",
    "optimized_solver = mipro_optimizer.compile(\n",
    "    AdvancedMathSolver(),\n",
    "    **compile_kwargs,\n",
    ")\n",
    "\n",
    "print(\"\u2713 MIPRO optimization complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0393aa",
   "metadata": {},
   "source": [
    "## 5. Evaluation with Concurrent Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0960988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all approaches\n",
    "evaluator = Evaluator(\n",
    "    metric_fn=gsm8k_metric, \n",
    "    show_progress=True, \n",
    "    verbose=False, \n",
    "    max_concurrent=2  # Lower concurrency reduces local parse/truncation errors\n",
    ")\n",
    "\n",
    "# Zero-shot baseline\n",
    "zero_shot = create_baseline(\"zero-shot\", \"gsm8k\", ollama_lm)\n",
    "zero_shot_result = evaluator.evaluate(\n",
    "    zero_shot, dev_examples, \"Zero-Shot (Ollama)\", \"gsm8k\"\n",
    ")\n",
    "\n",
    "# Few-shot baseline\n",
    "few_shot = create_baseline(\"few-shot\", \"gsm8k\", ollama_lm, num_examples=3)\n",
    "few_shot_result = evaluator.evaluate(\n",
    "    few_shot, dev_examples, \"Few-Shot (Ollama)\", \"gsm8k\"\n",
    ")\n",
    "\n",
    "# DSPy optimized\n",
    "dspy_result = evaluator.evaluate(\n",
    "    optimized_solver, dev_examples, \"DSPy MIPRO (Ollama)\", \"gsm8k\"\n",
    ")\n",
    "\n",
    "print(\"\\nResults Summary:\")\n",
    "print(f\"Zero-Shot: {zero_shot_result.accuracy:.1%}\")\n",
    "print(f\"Few-Shot: {few_shot_result.accuracy:.1%}\")\n",
    "print(f\"DSPy MIPRO: {dspy_result.accuracy:.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2efacbc",
   "metadata": {},
   "source": [
    "## 6. Inspect Optimized Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect what MIPRO learned\n",
    "print(\"Optimized Program Structure:\")\n",
    "print(optimized_solver)\n",
    "\n",
    "# Test on a few examples\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i in range(3):\n",
    "    example = dev_examples[i]\n",
    "    pred = optimized_solver(question=example.question)\n",
    "    correct = gsm8k_metric(example, pred) > 0.5\n",
    "    print(f\"\\nExample {i+1}: {'\u2713' if correct else '\u2717'}\")\n",
    "    print(f\"Question: {example.question[:60]}...\")\n",
    "    print(f\"Predicted: {pred.answer}\")\n",
    "    print(f\"Expected: {example.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60661e",
   "metadata": {},
   "source": [
    "## 7. Advanced DSPy Insights\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **MIPRO vs BootstrapFewShot**: MIPRO generates multiple candidate programs and uses Bayesian optimization to find the best one\n",
    "2. **Chain-of-Thought**: Explicit reasoning steps help local models perform better\n",
    "3. **Local Models**: Ollama models can achieve good performance with proper optimization\n",
    "4. **Concurrent Processing**: Speeds up both optimization and evaluation\n",
    "\n",
    "### Advanced Techniques Used\n",
    "\n",
    "- **MIPRO Optimizer**: Multi-instructor prompt optimization\n",
    "- **ChainOfThought Signature**: Forces step-by-step reasoning\n",
    "- **Bayesian Optimization**: Efficiently searches prompt space\n",
    "- **Parallel Processing**: Concurrent API calls for speed\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "- Try different local models (Mixtral, Llama variants)\n",
    "- Experiment with assertion-based optimization\n",
    "- Add multi-stage reasoning pipelines\n",
    "- Implement custom metrics and constraints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
